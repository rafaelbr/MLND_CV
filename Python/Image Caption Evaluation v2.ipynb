{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from picturedata.generator import DataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector, merge, Activation, Flatten, GRU, Input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples : 4745052\n",
      "Vocabulary size: 44537\n",
      "Maximum caption length: 51\n"
     ]
    }
   ],
   "source": [
    "generator = DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:13: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  del sys.path[0]\n",
      "/home/ubuntu/.local/lib/python2.7/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "image_input = Input(shape=(1000,))\n",
    "image_model = Dense(embedding_dim, input_dim=1000, activation='relu')(image_input)\n",
    "\n",
    "image_model = RepeatVector(generator.getMaxCapLen())(image_model)\n",
    "\n",
    "language_input = Input(shape=(generator.getMaxCapLen(),))\n",
    "language_model = Embedding(generator.getVocabSize(), 256, input_length=generator.getMaxCapLen())(language_input)\n",
    "language_model = LSTM(256, return_sequences=True)(language_model)\n",
    "#language_model.add(GRU(128, return_sequences=True))\n",
    "language_model = TimeDistributed(Dense(embedding_dim))(language_model)\n",
    "\n",
    "output = merge([image_model, language_model], mode='concat')\n",
    "output = LSTM(1000, return_sequences=False)(output)\n",
    "#model.add(GRU(256, return_sequences=False))\n",
    "output = Dense(generator.getVocabSize())(output)\n",
    "output = Activation('softmax')(output)\n",
    "\n",
    "model = Model(inputs=[image_input, language_input], outputs=[output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('Models/Weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 51)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_1 (InputLayer)             (None, 1000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 51, 256)       11401472    input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           128128      input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 51, 256)       525312      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)   (None, 51, 128)       0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistribu (None, 51, 128)       32896       lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 51, 256)       0           repeat_vector_1[0][0]            \n",
      "                                                                   time_distributed_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 1000)          5028000     merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 44537)         44581537    lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 44537)         0           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 61,697,345\n",
      "Trainable params: 61,697,345\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.78s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "annFile_train = \"annotations/captions_train2014.json\"\n",
    "\n",
    "coco = COCO(annFile_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgIds = coco.getImgIds()\n",
    "annIds = coco.getAnnIds(imgIds)\n",
    "\n",
    "imgs = coco.loadImgs(imgIds)\n",
    "anns = coco.loadAnns(annIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_df = pd.DataFrame(imgs)\n",
    "anns_df = pd.DataFrame(anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_new = imgs_df.drop(['coco_url','date_captured','flickr_url','height','width','license'], axis=1)\n",
    "\n",
    "img_new.rename(columns={'id': 'image_id'}, inplace=True)\n",
    "\n",
    "anns_df['caption'] = anns_df['caption'].apply(lambda x: '<start>' + x + '<end>')\n",
    "\n",
    "df = pd.merge(anns_df, img_new, on='image_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt;People shopping in an open market for v...</td>\n",
       "      <td>262145</td>\n",
       "      <td>COCO_train2014_000000262145.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt;An open market full of people and piles...</td>\n",
       "      <td>262145</td>\n",
       "      <td>COCO_train2014_000000262145.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt;People are shopping at an open air prod...</td>\n",
       "      <td>262145</td>\n",
       "      <td>COCO_train2014_000000262145.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt;Large piles of carrots and potatoes at ...</td>\n",
       "      <td>262145</td>\n",
       "      <td>COCO_train2014_000000262145.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt;People shop for vegetables like carrots...</td>\n",
       "      <td>262145</td>\n",
       "      <td>COCO_train2014_000000262145.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption  image_id  \\\n",
       "0  <start>People shopping in an open market for v...    262145   \n",
       "1  <start>An open market full of people and piles...    262145   \n",
       "2  <start>People are shopping at an open air prod...    262145   \n",
       "3  <start>Large piles of carrots and potatoes at ...    262145   \n",
       "4  <start>People shop for vegetables like carrots...    262145   \n",
       "\n",
       "                         file_name  \n",
       "0  COCO_train2014_000000262145.jpg  \n",
       "1  COCO_train2014_000000262145.jpg  \n",
       "2  COCO_train2014_000000262145.jpg  \n",
       "3  COCO_train2014_000000262145.jpg  \n",
       "4  COCO_train2014_000000262145.jpg  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_files = set(df['file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
